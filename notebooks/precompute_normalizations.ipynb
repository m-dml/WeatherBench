{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "from src.train_nn_pytorch import Dataset\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('using CUDA !')\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "else:\n",
    "    print(\"CUDA not available\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "\n",
    "datadir = '/gpfs/work/nonnenma/data/forecast_predictability/weatherbench/5_625deg/'\n",
    "res_dir = '/gpfs/work/nonnenma/results/forecast_predictability/weatherbench/5_625deg/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-level fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [{'geopotential': ('z', [1, 10, 100, 200, 300, 400, 500, 600, 700, 850, 1000])},\n",
    "          {'temperature': ('t', [1, 10, 100, 200, 300, 400, 500, 600, 700, 850, 1000])},\n",
    "          {'u_component_of_wind': ('u', [1, 10, 100, 200, 300, 400, 500, 600, 700, 850, 1000])},\n",
    "          {'v_component_of_wind': ('v', [1, 10, 100, 200, 300, 400, 500, 600, 700, 850, 1000])}\n",
    "         ]\n",
    "\n",
    "for field in fields:\n",
    "\n",
    "    var_dict = field\n",
    "    print(var_dict.keys())    \n",
    "\n",
    "    x = xr.merge(\n",
    "    [xr.open_mfdataset(f'{datadir}/{var}/*.nc', combine='by_coords')\n",
    "     for var in var_dict.keys()],\n",
    "    fill_value=0  # For the 'tisr' NaNs\n",
    "    )\n",
    "    x = x.chunk({'time' : np.sum(x.chunks['time']), 'lat' : x.chunks['lat'], 'lon': x.chunks['lon']})\n",
    "\n",
    "    dg_train = Dataset(x.sel(time=slice('1979', '2015')), var_dict, lead_time=72, \n",
    "                       normalize=True, norm_subsample=1, \n",
    "                       target_vars=[list(field.keys())[0]], target_levels=[field[list(field.keys())[0]][1][0]])\n",
    "\n",
    "    print(dg_train.mean.values, dg_train.std.values, dg_train.level_names)\n",
    "    dg_train.mean.to_netcdf(res_dir + list(field.keys())[0] + '/mean_1979_2015.nc')\n",
    "    dg_train.std.to_netcdf(res_dir + list(field.keys())[0] + '/std_1979_2015.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constant fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = {'constants': ['lat2d','lon2d', 'lsm','orography', 'slt']} # note alphabetical ordering\n",
    "x = xr.merge(\n",
    "[xr.open_mfdataset(f'{datadir}/{var}/*.nc', combine='by_coords')\n",
    " for var in var_dict.keys()],\n",
    "fill_value=0  # For the 'tisr' NaNs\n",
    ")\n",
    "x = x.chunk({'lat' : x.chunks['lat'], 'lon': x.chunks['lon']})\n",
    "\n",
    "generic_level = xr.DataArray([1], coords={'level': [1]}, dims=['level'])\n",
    "time = xr.open_mfdataset(f'{datadir}/geopotential_500/*.nc', combine='by_coords').time.values\n",
    "data = []\n",
    "for _, params in var_dict.items():\n",
    "    for var in params:\n",
    "        data.append(x[var].expand_dims(\n",
    "            {'level': generic_level, 'time': time}, (1, 0)\n",
    "        ).astype(np.float32))\n",
    "data = xr.concat(data, 'level')\n",
    "data.level.values = field['constants']\n",
    "\n",
    "const_mean = data.isel(time=slice(0, None, 1)).mean(\n",
    "                ('time', 'lat', 'lon')).compute()\n",
    "const_std = data.isel(time=slice(0, None, 1)).std(\n",
    "                ('time', 'lat', 'lon')).compute()\n",
    "\n",
    "const_mean.to_netcdf(res_dir + list(field.keys())[0] + '/mean_1979_2015.nc')\n",
    "const_std.to_netcdf(res_dir + list(field.keys())[0] + '/std_1979_2015.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
