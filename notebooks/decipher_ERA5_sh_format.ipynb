{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# check spherical representation in ERA5\n",
    "- we can download atmospheric output fields of ERA5 in spectral representation (sh = spherical harmonics)\n",
    "- the data format however is hardly anywhere described\n",
    "- we'll go and reverse engineer the format from different spectral cutoffs !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "datadir = '/gpfs/work/nonnenma/data/forecast_predictability/weatherbench/5_625deg/'\n",
    "res_dir = '/gpfs/work/nonnenma/results/forecast_predictability/weatherbench/5_625deg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# downloading three different spectral resolutions of the same day parameter from MARS\n",
    "# - level-type 'pressure level' pl (e.g. versus 'model level' ml)\n",
    "# - temperature (parameter id '130')\n",
    "# - stream: 'oper' for operational forecast\n",
    "# - type analysis 'an' (e.g. versus 'forecast' fc)\n",
    "# - two pressure levels: 500 and 850 hPa\n",
    "# - whole month 2016-01-01 to 2016-01-31 (=744h)\n",
    "\n",
    "\"\"\"\n",
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "fn = 'test_temperature_JAN_2016_MARS_T19'\n",
    "c.retrieve('reanalysis-era5-complete', {\n",
    "    'class': 'ea',\n",
    "    'date': '2016-01-01/to/2016-01-31',\n",
    "    'expver': '1',\n",
    "    'levelist': '500/850',\n",
    "    'levtype': 'pl',\n",
    "    'param': '130.128',\n",
    "    'stream': 'oper',\n",
    "    'truncation' : '19',\n",
    "    'time': '00:00:00/01:00:00/02:00:00/03:00:00/04:00:00/05:00:00/06:00:00/07:00:00/08:00:00/09:00:00/10:00:00/11:00:00/12:00:00/13:00:00/14:00:00/15:00:00/16:00:00/17:00:00/18:00:00/19:00:00/20:00:00/21:00:00/22:00:00/23:00:00',\n",
    "    'type': 'an',\n",
    "}, datadir + fn + '.grib')\n",
    "\n",
    "c = cdsapi.Client()\n",
    "fn = 'test_temperature_JAN_2016_MARS_T179'\n",
    "c.retrieve('reanalysis-era5-complete', {\n",
    "    'class': 'ea',\n",
    "    'date': '2016-01-01/to/2016-01-31',\n",
    "    'expver': '1',\n",
    "    'levelist': '500/850',\n",
    "    'levtype': 'pl',\n",
    "    'param': '130.128',\n",
    "    'stream': 'oper',\n",
    "    'truncation' : '179',\n",
    "    'time': '00:00:00/01:00:00/02:00:00/03:00:00/04:00:00/05:00:00/06:00:00/07:00:00/08:00:00/09:00:00/10:00:00/11:00:00/12:00:00/13:00:00/14:00:00/15:00:00/16:00:00/17:00:00/18:00:00/19:00:00/20:00:00/21:00:00/22:00:00/23:00:00',\n",
    "    'type': 'an',\n",
    "}, datadir + fn + '.grib')\n",
    "\n",
    "\n",
    "c = cdsapi.Client()\n",
    "fn = 'test_temperature_JAN_2016_MARS'\n",
    "c.retrieve('reanalysis-era5-complete', {\n",
    "    'class': 'ea',\n",
    "    'date': '2016-01-01/to/2016-01-31',\n",
    "    'expver': '1',\n",
    "    'levelist': '500/850',\n",
    "    'levtype': 'pl',\n",
    "    'param': '130.128',\n",
    "    'stream': 'oper',\n",
    "    #'truncation' : '179', # no truncation gives T639, the inherent resolution of the IFS model !\n",
    "    'time': '00:00:00/01:00:00/02:00:00/03:00:00/04:00:00/05:00:00/06:00:00/07:00:00/08:00:00/09:00:00/10:00:00/11:00:00/12:00:00/13:00:00/14:00:00/15:00:00/16:00:00/17:00:00/18:00:00/19:00:00/20:00:00/21:00:00/22:00:00/23:00:00',\n",
    "    'type': 'an',\n",
    "}, datadir + fn + '.grib')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "fn = 'test_temperature_JAN_2016_MARS_T19'\n",
    "x19 = xr.open_dataset(datadir + fn + '.grib', engine='cfgrib')\n",
    "\n",
    "\n",
    "fn = 'test_temperature_JAN_2016_MARS_T63'\n",
    "x63 = xr.open_dataset(datadir + fn + '.grib', engine='cfgrib')\n",
    "\n",
    "\n",
    "fn = 'test_temperature_JAN_2016_MARS_T179'\n",
    "x179 = xr.open_dataset(datadir + fn + '.grib', engine='cfgrib')\n",
    "\n",
    "fn = 'test_temperature_JAN_2016_MARS' # this is T639\n",
    "x639 = xr.open_dataset(datadir + fn + '.grib', engine='cfgrib')\n",
    "\n",
    "# let's check output shapes\n",
    "x19.t.shape, x179.t.shape, x639.t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## figuring out the data format\n",
    "- it is outputshape = (T+1) * (T+2), e.g. 420 = (19+1) * (19+2)\n",
    "- the spherical coefficients are complex, hence there's probably two floats per spherical harmonic\n",
    "- hypothesis: first half is REAL parts stored in an upper triangular (T+1)x(T+1) matrix for harmonics l=0,...,T, second half is COMPLEX parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def comp(T, values): # quick & dirty function to put values into (T+1)x(T+1) upper triangular matrix.\n",
    "    \n",
    "    T_ = T+1\n",
    "    M = np.zeros((T_, T_))\n",
    "    tri = np.ones((T_,T_))\n",
    "    \n",
    "    for i in range(T_):\n",
    "        for j in range(T_):\n",
    "            if j>i:\n",
    "                tri[i,j] = 0\n",
    "    idxi, idxj = np.where(tri.T) # get indices of upper triangular matrix\n",
    "\n",
    "    for idx in range( int(T_*(T_+1) /2)):\n",
    "        i, j = idxi[idx], idxj[idx]\n",
    "        M[i,j] = values[idx] # assign values to location in upper triangular matrix\n",
    "        #assert i >= j\n",
    "\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute full upper triangular matrices, compare over regions that should overlap (up to T=19+1, 179+1)\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "\n",
    "# tenetative REAL parts of coefficients\n",
    "\n",
    "Mr19r = comp(T=19, values=x19.t.values[0,0,:][0::2])\n",
    "Mr179r = comp(T=179, values=x179.t.values[0,0,:][0::2])\n",
    "Mr639r = comp(T=639, values=x639.t.values[0,0,:][0::2])\n",
    "\n",
    "assert np.all(Mr19r[:20, :20]==Mr179r[:20, :20])\n",
    "assert np.all(Mr19r[:20, :20]==Mr639r[:20, :20])\n",
    "print(np.max(np.abs(Mr179r[:180, :180]-Mr639r[:180, :180])))\n",
    "\n",
    "\n",
    "\n",
    "# tenetative COMPLEX parts of coefficients\n",
    "\n",
    "Mr19i = comp(T=19, values=x19.t.values[0,0,:][1::2])\n",
    "Mr179i = comp(T=179, values=x179.t.values[0,0,:][1::2])\n",
    "Mr639i = comp(T=639, values=x639.t.values[0,0,:][1::2])\n",
    "\n",
    "assert np.all(Mr19i[:20, :20]==Mr179i[:20, :20])\n",
    "assert np.all(Mr19i[:20, :20]==Mr639i[:20, :20])\n",
    "print(np.max(np.abs(Mr179i[:180, :180]-Mr639i[:180, :180])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(np.log(np.abs(Mr179[:20, :20])))\n",
    "plt.title('T179')\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(np.log(np.abs(Mr19[:20, :20])))\n",
    "plt.title('T19')\n",
    "\"\"\"\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(np.log(np.abs(Mr639r[:180, :180])))\n",
    "plt.title('T639')\n",
    "plt.ylabel('tentative REAL parts')\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(np.log(np.abs(Mr179r[:180, :180])))\n",
    "plt.title('T179')\n",
    "plt.ylabel('tentative REAL parts')\n",
    "\n",
    "\"\"\"\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(np.log(np.abs(Mr179[:20, :20])))\n",
    "plt.title('T179')\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(np.log(np.abs(Mr19[:20, :20])))\n",
    "plt.title('T19')\n",
    "\"\"\"\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(np.log(np.abs(Mr639i[:180, :180])))\n",
    "plt.title('T639')\n",
    "plt.ylabel('tentative COMPLEX parts')\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(np.log(np.abs(Mr179i[:180, :180])))\n",
    "plt.title('T179')\n",
    "plt.ylabel('tentative COMPLEX parts')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### track down differences between T179 and T639\n",
    "- there's seeminlgy some small differences between T179 and T639, let's find out if they're negligible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow( np.abs(Mr179r) )\n",
    "plt.title('real part')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow( np.abs(Mr179i) )\n",
    "plt.title('imaginary part')\n",
    "\n",
    "plt.suptitle('full coefficient matrix for T179')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# looks like differences starts after the 20th harmonic !\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "x = np.zeros((180,180))\n",
    "idxi, idxj = np.where( Mr179r[:180, :180] != Mr639r[:180, :180] )\n",
    "for i in range(len(idxi)):\n",
    "    x[idxi[i], idxj[i]] = 1\n",
    "plt.imshow(x[:30, :30])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "x = np.zeros((180,180))\n",
    "idxi, idxj = np.where( Mr179i[:180, :180] != Mr639i[:180, :180] )\n",
    "for i in range(len(idxi)):\n",
    "    x[idxi[i], idxj[i]] = 1\n",
    "plt.imshow(x[:30, :30])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which values differ by more than 1% of the T639 value ?\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(  (np.abs(Mr179r[:180, :180] - Mr639r[:180, :180]) /  Mr639r[:180, :180]) > 0.01 )\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(  (np.abs(Mr179i[:180, :180] - Mr639i[:180, :180]) /  Mr639i[:180, :180]) > 0.01 )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# s2cnn corner\n",
    "- understanding  and fixing the differences in encoding of spherical coefficients $\\psi^m_l(t)$ between the s2cnn package and ERA5\n",
    "- ERA5 only stores $\\psi^m_l(t)$ only for positive $m$ (it is $\\psi^{-m}_l(t) = 1/(-1)^m [\\psi^m_l(t)]^*$). s2cnn expects coefficients for positive and negative $m$.\n",
    "- ERA5 stores real and imaginary parts of coefficients intermittently, s2cnn has a 'complex' length-2 tensor axis \n",
    "- ERA5 arranges the coefficients for different $m,l$ as if read linearly from an upper triangular matrix, whereas s2cnn aranges them sorted by $l$ (i.e. as if reading along columns $M[l,:l]$, then rows $M[:l,l]$ of a matrix with all coefficients) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function reads in spherical coefficients from ERA5 in 'values' and returns them ordered as for s2cnn \n",
    "def translate_idx(T, Tnew=None):\n",
    "    \n",
    "    Tnew = T if Tnew is None else Tnew    \n",
    "    T_, Tnew_ = T+1, Tnew+1\n",
    "\n",
    "    # get indices of lower triangular matrix\n",
    "    idx_in_i, idx_in_j = np.where(np.triu(np.ones((T_,T_)))) \n",
    "\n",
    "    # get indices to read out elements of full coefficient matrix\n",
    "    idx_out_i, idx_out_j = np.zeros(Tnew_**2,dtype=np.int), np.zeros(Tnew_**2, dtype=np.int)\n",
    "    for l in range(Tnew_):\n",
    "        # first read indices m = -l : -1 from lower triangle, then  m = 0 : l from upper\n",
    "        idx_out_i[l**2 : l**2 + 2*l + 1] = np.asarray(np.concatenate([l*np.ones(l), np.arange(l+1)]), dtype=np.int)\n",
    "        # note there's a shift on the column indices in lower triangle due to Mc[1:,-1] = M[1:, 1:] above\n",
    "        idx_out_j[l**2 : l**2 + 2*l + 1] = np.asarray(np.concatenate([np.arange(l)[::-1], l**np.ones(l+1)]), dtype=np.int)\n",
    "    \n",
    "    return idx_in_i, idx_in_j, idx_out_i, idx_out_j\n",
    "    \n",
    "def cohmp(T, values, idcs=None, Tnew=None): # quick & dirty function to put values into (T+1)x(T+1) upper triangular matrix.\n",
    "\n",
    "    Tnew = T if Tnew is None else Tnew    \n",
    "    T_, Tnew_ = T+1, Tnew+1\n",
    "    idx_in_i, idx_in_j, idx_out_i, idx_out_j = translate_idx(T,Tnew) if idcs is None else idcs\n",
    "    \n",
    "    # read stored spherical coefficients into upper triangular matrix \n",
    "    M = np.zeros((T_, T_, 2))\n",
    "    for i in range(2):\n",
    "        M[idx_in_i,idx_in_j,i] = values[i::2]\n",
    "    M = M[:Tnew_, :Tnew_]\n",
    "\n",
    "    # retrieve and store spherical coefficients for negative m\n",
    "    ms = (np.arange(1,Tnew_).reshape(-1,1)+np.array([0,1]))[:,None,:] \n",
    "    M[1:,:-1,:] += (M[1:, 1:,:] / (-1)**ms).transpose(1,0,2) # (-1)^m on the *columns* (i.e. along 'm' axis)\n",
    "        \n",
    "    # now read out elements of M in correct order ...\n",
    "    out = np.vstack([M[idx_out_i, idx_out_j,i] for i in range(2)]).T.reshape(-1,1,2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s2cnn.soft.s2_fft import s2_ifft\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = 736 # time index (in h)\n",
    "lvl = 0 # level index (indexing [500, 850] hPa)\n",
    "\n",
    "idcs63 = translate_idx(T=639, Tnew=63)\n",
    "ft = cohmp(T=639, Tnew=63, values=x639.t.values[t,lvl,:], idcs=idcs63)\n",
    "\n",
    "print('fourier transform shape: ', ft.shape)\n",
    "\n",
    "x = s2_ifft(torch.tensor(ft, dtype=torch.float32), for_grad=False, b_out=None)\n",
    "plt.figure(figsize=(16,8))\n",
    "titles = ['real part', 'imaginary part']\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(x[0,:,:,i])\n",
    "    plt.colorbar()\n",
    "    plt.title(titles[i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparison images with weatherbench data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from s2cnn.soft.s2_fft import s2_ifft\n",
    "\n",
    "for t in [0, 300, 736]:\n",
    "    plt.figure(figsize=(16,15))\n",
    "    for lvl in range(2):\n",
    "\n",
    "        ft = cohmp(T=639, Tnew=63, values=x639.t.values[t,lvl,:], idcs=idcs63)\n",
    "        print('fourier transform shape: ', ft.shape)\n",
    "\n",
    "        x = s2_ifft(torch.tensor(ft, dtype=torch.float32), for_grad=False, b_out=None)\n",
    "        titles = ['ifft(ERA5)', 'imaginary part']\n",
    "        for i in range(1):\n",
    "            plt.subplot(2,2,i+1 + 2*lvl)\n",
    "            plt.imshow(x[0,:,:,i])\n",
    "            plt.title(titles[i])\n",
    "            plt.colorbar()\n",
    "        if lvl == 0:\n",
    "            plt.ylabel('500 hPa')\n",
    "        else:\n",
    "            plt.ylabel('850 hPa')\n",
    "\n",
    "        datadir = '/gpfs/work/nonnenma/data/forecast_predictability/weatherbench/5_625deg/'\n",
    "        var_dict = {'temperature': ('t', [500, 850])}\n",
    "        x = xr.merge( # lazy: use xr.merge to get hour counts per year from chunk size\n",
    "        [xr.open_mfdataset(f'{datadir}/{var}/*2016*.nc', combine='by_coords')\n",
    "         for var in var_dict.keys()],\n",
    "        fill_value=0  # For the 'tisr' NaNs\n",
    "        )\n",
    "        x = x.sel(level=[500, 850]).t.values\n",
    "        plt.subplot(2,2,2 + 2*lvl)\n",
    "        plt.imshow(np.flipud(np.hstack([x[t,lvl,:,32:],x[t,lvl,:,:32]])), aspect='auto')\n",
    "        plt.colorbar()\n",
    "        plt.title('weatherbench comparison frame')\n",
    "        plt.suptitle(f'January 2016, t = {t}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plug into (custom) convolutional layer for S2CNN\n",
    "- S2Convolution() assumes input is already in grid-space, but here we got spherical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "import time\n",
    "\n",
    "from s2cnn.soft.so3_fft import SO3_ifft_real\n",
    "from s2cnn import s2_mm\n",
    "from s2cnn import s2_rft\n",
    "\n",
    "from s2cnn import s2_near_identity_grid\n",
    "from s2cnn import S2Convolution\n",
    "\n",
    "\n",
    "def so3_onto_s2(x):\n",
    "    \"\"\"\n",
    "    Integrate a signal on SO(3) along gamma to obtain \n",
    "    \n",
    "    :param x: [..., beta, alpha, gamma] (..., 2b, 2b, 2b)\n",
    "    :return y: [..., beta, alpha] (..., 2b, 2b)\n",
    "    \"\"\"\n",
    "    assert x.size(-1) == x.size(-2)\n",
    "    assert x.size(-2) == x.size(-3)\n",
    "\n",
    "    b = x.size(-1) // 2\n",
    "\n",
    "    w = _setup_so3_integrate(b, device_type=x.device.type, device_index=x.device.index)  # [beta]\n",
    "\n",
    "    x = torch.sum(x, dim=-1).squeeze(-1)  # [..., beta, alpha]\n",
    "    x = torch.sum(x, dim=-1).squeeze(-1)  # [..., beta]\n",
    "\n",
    "    sz = x.size()\n",
    "    x = x.view(-1, 2 * b)\n",
    "    w = w.view(2 * b, 1)\n",
    "    x = torch.mm(x, w).squeeze(-1)\n",
    "    x = x.view(*sz[:-1])\n",
    "    return x\n",
    "\n",
    "\n",
    "class FTConvolution(S2Convolution):\n",
    "    \n",
    "    def __init__(self, nfeature_in, nfeature_out, b_in, b_out, grid):\n",
    "        '''\n",
    "        :param nfeature_in: number of input fearures\n",
    "        :param nfeature_out: number of output features\n",
    "        :param b_in: input bandwidth (precision of the input SOFT grid)\n",
    "        :param b_out: output bandwidth\n",
    "        :param grid: points of the sphere defining the kernel, tuple of (alpha, beta)'s\n",
    "        '''\n",
    "        super(FTConvolution, self).__init__(nfeature_in, nfeature_out, b_in, b_out, grid)\n",
    "        \n",
    "    def forward(self, x):  # pylint: disable=W\n",
    "        ''' We rewrite the S2 convolution to start from x already Fourier-transformed\n",
    "        :x:      [b_in**2, batch, feature_in,  complex]\n",
    "        :return: [batch, feature_out, beta, alpha, gamma]\n",
    "        '''\n",
    "        assert x.size(0) == self.b_in**2\n",
    "        assert x.size(2) == self.nfeature_in\n",
    "        assert x.size(3) == 2\n",
    "\n",
    "        y = s2_rft(self.kernel * self.scaling, self.b_out, self.grid)  # [l * m, feature_in, feature_out, complex]\n",
    "\n",
    "        y = torch.as_tensor(y, dtype=torch.float64) # because reasons...\n",
    "                    \n",
    "        print('(x,y)', (x.shape, y.shape))\n",
    "            \n",
    "        z = s2_mm(x, y)  # [l * m * n, batch, feature_out, complex]\n",
    "        \n",
    "        print('z.shape', z.shape)\n",
    "        z = SO3_ifft_real.apply(z)  # [batch, feature_out, beta, alpha, gamma]\n",
    "        z = z + self.bias\n",
    "\n",
    "        return z\n",
    "\n",
    "# define convolutional layer \n",
    "\n",
    "T = 63\n",
    "b_in = T+1\n",
    "b_out = T+1\n",
    "grid_s2 = s2_near_identity_grid()\n",
    "        \n",
    "conv1 = FTConvolution(nfeature_in=2, nfeature_out=4, b_in=b_in, b_out=b_out, grid=grid_s2)\n",
    "\n",
    "# load and translate input data\n",
    "ts, lvls, ft = [0,1,2], [0,1], []\n",
    "idcs63 = translate_idx(T=639, Tnew=63)\n",
    "\n",
    "# stacking inputs (cohmp() not yet parallelized)\n",
    "for t in ts:\n",
    "    ft.append(np.concatenate(\n",
    "        [cohmp(T=639, Tnew=63, values=x639.t.values[t,lvl,:], idcs=idcs63) for lvl in lvls],\n",
    "        axis=1\n",
    "    ))\n",
    "ft = np.stack(ft, axis=1)\n",
    "print('ft.shape', ft.shape)\n",
    "              \n",
    "print('\\n beginning convolution ! \\n')\n",
    "t = time.time()\n",
    "out = conv1.forward(torch.tensor(ft, requires_grad=False, dtype=torch.float64))\n",
    "print(f'- finished in {time.time()-t}s -')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s2cnn.soft.so3_fft import SO3_fft_real, SO3_ifft_real\n",
    "x = SO3_fft_real.apply(torch.as_tensor(out, dtype=torch.float32), b_out)  # [l * m * n, batch, feature_in, complex]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "years = ['1979', '1980', '1981', '1982', '1983', '1984',\n",
    "         '1985', '1986', '1987', '1988', '1989', '1990',\n",
    "         '1991', '1992', '1993', '1994', '1995', '1996',\n",
    "         '1997', '1998', '1999', '2000', '2001', '2002',\n",
    "         '2003', '2004', '2005', '2006', '2007', '2008',\n",
    "         '2009', '2010', '2011', '2012', '2013', '2014',\n",
    "         '2015', '2016', '2017', '2018'\n",
    "        ]\n",
    "\n",
    "variables = [\n",
    "            'geopotential', 'potential_vorticity', 'relative_humidity',\n",
    "            'specific_humidity', 'temperature', 'u_component_of_wind',\n",
    "            'v_component_of_wind', 'vorticity',\n",
    "        ]\n",
    "\n",
    "months = [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "        ]\n",
    "\n",
    "days = [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "            '13', '14', '15',\n",
    "            '16', '17', '18',\n",
    "            '19', '20', '21',\n",
    "            '22', '23', '24',\n",
    "            '25', '26', '27',\n",
    "            '28', '29', '30',\n",
    "            '31',\n",
    "        ]\n",
    "\n",
    "fn = 'test_temperature_1979'\n",
    "years_selected = [ years[0] ]\n",
    "variables_selected = [ variables[4] ]\n",
    "months_selected = [ months[0] ]\n",
    "days_selected = [ days[0] ]\n",
    "request = {\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'grib',\n",
    "        'variable': variables_selected, \n",
    "        'pressure_level': [\n",
    "            '1', '10', '100',\n",
    "            '200', '300', '400',\n",
    "            '500', '600', '700',\n",
    "            '850', '1000',\n",
    "        ],\n",
    "        'year': years_selected,\n",
    "        'month': months_selected,\n",
    "        'day': days_selected,\n",
    "        'time': [\n",
    "            '00:00', '01:00', '02:00',\n",
    "            '03:00', '04:00', '05:00',\n",
    "            '06:00', '07:00', '08:00',\n",
    "            '09:00', '10:00', '11:00',\n",
    "            '12:00', '13:00', '14:00',\n",
    "            '15:00', '16:00', '17:00',\n",
    "            '18:00', '19:00', '20:00',\n",
    "            '21:00', '22:00', '23:00',\n",
    "        ],\n",
    "    }\n",
    "\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-pressure-levels',\n",
    "    request,\n",
    "    datadir + fn + '.grib')\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
