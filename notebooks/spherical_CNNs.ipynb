{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# get S2CNN to work on weatherbench and ERA5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "datadir = '/gpfs/work/nonnenma/data/forecast_predictability/weatherbench/5_625deg/'\n",
    "res_dir = '/gpfs/work/nonnenma/results/forecast_predictability/weatherbench/5_625deg/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load ERA5 states here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "fn = 'test_temperature_JAN_2016_MARS_T19'\n",
    "x19 = xr.open_dataset(datadir + fn + '.grib', engine='cfgrib')\n",
    "\n",
    "\n",
    "fn = 'test_temperature_JAN_2016_MARS_T63'\n",
    "x63 = xr.open_dataset(datadir + fn + '.grib', engine='cfgrib')\n",
    "\n",
    "\n",
    "fn = 'test_temperature_JAN_2016_MARS_T179'\n",
    "x179 = xr.open_dataset(datadir + fn + '.grib', engine='cfgrib')\n",
    "\n",
    "fn = 'test_temperature_JAN_2016_MARS' # this is T639\n",
    "x639 = xr.open_dataset(datadir + fn + '.grib', engine='cfgrib')\n",
    "\n",
    "# let's check output shapes\n",
    "x19.t.shape, x179.t.shape, x639.t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indexing  translations between ERA5 ans S2CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function reads in spherical coefficients from ERA5 in 'values' and returns them ordered as for s2cnn \n",
    "def translate_idx(T, Tnew=None):\n",
    "    \n",
    "    Tnew = T if Tnew is None else Tnew    \n",
    "    T_, Tnew_ = T+1, Tnew+1\n",
    "\n",
    "    # get indices of lower triangular matrix\n",
    "    idx_in_i, idx_in_j = np.where(np.triu(np.ones((T_,T_)))) \n",
    "\n",
    "    # get indices to read out elements of full coefficient matrix\n",
    "    idx_out_i, idx_out_j = np.zeros(Tnew_**2,dtype=np.int), np.zeros(Tnew_**2, dtype=np.int)\n",
    "    for l in range(Tnew_):\n",
    "        # first read indices m = -l : -1 from lower triangle, then  m = 0 : l from upper\n",
    "        idx_out_i[l**2 : l**2 + 2*l + 1] = np.asarray(np.concatenate([l*np.ones(l), np.arange(l+1)]), dtype=np.int)\n",
    "        # note there's a shift on the column indices in lower triangle due to Mc[1:,-1] = M[1:, 1:] above\n",
    "        idx_out_j[l**2 : l**2 + 2*l + 1] = np.asarray(np.concatenate([np.arange(l)[::-1], l**np.ones(l+1)]), dtype=np.int)\n",
    "    \n",
    "    return idx_in_i, idx_in_j, idx_out_i, idx_out_j\n",
    "    \n",
    "def cohmp(T, values, idcs=None, Tnew=None): # quick & dirty function to put values into (T+1)x(T+1) upper triangular matrix.\n",
    "\n",
    "    Tnew = T if Tnew is None else Tnew    \n",
    "    T_, Tnew_ = T+1, Tnew+1\n",
    "    idx_in_i, idx_in_j, idx_out_i, idx_out_j = translate_idx(T,Tnew) if idcs is None else idcs\n",
    "    \n",
    "    # read stored spherical coefficients into upper triangular matrix \n",
    "    M = np.zeros((T_, T_, 2))\n",
    "    for i in range(2):\n",
    "        M[idx_in_i,idx_in_j,i] = values[i::2]\n",
    "    M = M[:Tnew_, :Tnew_]\n",
    "\n",
    "    # retrieve and store spherical coefficients for negative m\n",
    "    ms = (np.arange(1,Tnew_).reshape(-1,1)+np.array([0,1]))[:,None,:] \n",
    "    M[1:,:-1,:] += (M[1:, 1:,:] / (-1)**ms).transpose(1,0,2) # (-1)^m on the *columns* (i.e. along 'm' axis)\n",
    "        \n",
    "    # now read out elements of M in correct order ...\n",
    "    out = np.vstack([M[idx_out_i, idx_out_j,i] for i in range(2)]).T.reshape(-1,1,2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# redefining S2CNN classes for grids with Nx2N grid point\n",
    "- CUDA version not even started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s2cnn.soft.s2_fft import _setup_wigner\n",
    "\n",
    "def s2_fft_half_height(x, for_grad=False, b_out=None):\n",
    "    '''\n",
    "    :param x: [..., beta, alpha, complex]\n",
    "    :return:  [l * m, ..., complex]\n",
    "    '''\n",
    "    print('x.shape', x.shape)    \n",
    "    assert x.size(-1) == 2\n",
    "    b_in_m = x.size(-3)  # vertical resolution (latittudes)\n",
    "    b_in_l = 2 * b_in    # horizontal resolution (longitudes)\n",
    "    assert x.size(-2) == b_in_l\n",
    "    if b_out is None:\n",
    "        b_out = b_in\n",
    "    assert b_out <= b_in_l\n",
    "    batch_size = x.size()[:-3]\n",
    "\n",
    "    x = x.view(-1, b_in_m, b_in_l, 2)  # [batch, beta, alpha, complex]\n",
    "\n",
    "    '''\n",
    "    :param x: [batch, beta, alpha, complex] (nbatch, b_in, 2 * b_in, 2)\n",
    "    :return: [l * m, batch, complex] (b_out**2, nbatch, 2)\n",
    "    '''\n",
    "    nspec = b_out ** 2\n",
    "    nbatch = x.size(0)\n",
    "\n",
    "    wigner = _setup_wigner(b_in_m, nl=b_out, weighted=not for_grad, device=x.device)\n",
    "    wigner = wigner.view(b_in_m, -1)  # [beta, l * m] (b_in, nspec)\n",
    "\n",
    "    x = torch.fft(x, 1)  # [batch, beta, m, complex]\n",
    "\n",
    "    output = x.new_empty((nspec, nbatch, 2))\n",
    "    if x.is_cuda and x.dtype == torch.float32:\n",
    "        import s2cnn.utils.cuda as cuda_utils\n",
    "        cuda_kernel = _setup_s2fft_cuda_kernel(b=b_in, nspec=nspec, nbatch=nbatch, device=x.device.index)\n",
    "        stream = cuda_utils.Stream(ptr=torch.cuda.current_stream().cuda_stream)\n",
    "        cuda_kernel(block=(1024, 1, 1),\n",
    "                    grid=(cuda_utils.get_blocks(nspec * nbatch, 1024), 1, 1),\n",
    "                    args=[x.contiguous().data_ptr(), wigner.contiguous().data_ptr(), output.data_ptr()],\n",
    "                    stream=stream)\n",
    "        # [l * m, batch, complex]\n",
    "    else:\n",
    "        for l in range(b_out):\n",
    "            s = slice(l ** 2, l ** 2 + 2 * l + 1)\n",
    "            xx = torch.cat((x[:, :, -l:], x[:, :, :l + 1]), dim=2) if l > 0 else x[:, :, :1]\n",
    "            output[s] = torch.einsum(\"bm,zbmc->mzc\", (wigner[:, s], xx))\n",
    "\n",
    "    output = output.view(-1, *batch_size, 2)  # [l * m, ..., complex] (nspec, ..., 2)\n",
    "    return output\n",
    "\n",
    "\n",
    "def s2_ifft_half_height(x, for_grad=False, b_out=None):\n",
    "    '''\n",
    "    :param x: [l * m, ..., complex]\n",
    "    '''\n",
    "    assert x.size(-1) == 2\n",
    "    nspec = x.size(0)\n",
    "    b_in = round(nspec ** 0.5)\n",
    "    assert nspec == b_in ** 2\n",
    "    if b_out is None:\n",
    "        b_out = b_in   # horizontal resolution (longitudes)\n",
    "    b_out_m = b_out//2 # vertical resolution (latittudes)\n",
    "    assert b_out >= b_in\n",
    "    batch_size = x.size()[1:-1]\n",
    "\n",
    "    x = x.view(nspec, -1, 2)  # [l * m, batch, complex] (nspec, nbatch, 2)\n",
    "\n",
    "    '''\n",
    "    :param x: [l * m, batch, complex] (b_in**2, nbatch, 2)\n",
    "    :return: [batch, beta, alpha, complex] (nbatch, 2 b_out, 2 * b_out, 2)\n",
    "    '''\n",
    "    nbatch = x.size(1)\n",
    "\n",
    "    wigner = _setup_wigner(b_out_m, nl=b_in, weighted=for_grad, device=x.device)\n",
    "    wigner = wigner.view(2 * b_out_m, -1)  # [beta, l * m] (b_out, nspec)\n",
    "\n",
    "    if x.is_cuda and x.dtype == torch.float32:\n",
    "        import s2cnn.utils.cuda as cuda_utils\n",
    "        cuda_kernel = _setup_s2ifft_cuda_kernel(b=b_out, nl=b_in, nbatch=nbatch, device=x.device.index)\n",
    "        stream = cuda_utils.Stream(ptr=torch.cuda.current_stream().cuda_stream)\n",
    "        output = x.new_empty((nbatch, 2 * b_out, 2 * b_out, 2))\n",
    "        cuda_kernel(block=(1024, 1, 1),\n",
    "                    grid=(cuda_utils.get_blocks(nbatch * (2 * b_out) ** 2, 1024), 1, 1),\n",
    "                    args=[x.data_ptr(), wigner.data_ptr(), output.data_ptr()],\n",
    "                    stream=stream)\n",
    "        # [batch, beta, m, complex] (nbatch, 2 * b_out, 2 * b_out, 2)\n",
    "    else:\n",
    "        output = x.new_zeros((nbatch, 2 * b_out_m, 2 * b_out, 2))\n",
    "        for l in range(b_in):\n",
    "            s = slice(l ** 2, l ** 2 + 2 * l + 1)\n",
    "            out = torch.einsum(\"mzc,bm->zbmc\", (x[s], wigner[:, s]))\n",
    "            output[:, :, :l + 1] += out[:, :, -l - 1:]\n",
    "            if l > 0:\n",
    "                output[:, :, -l:] += out[:, :, :l]\n",
    "\n",
    "    output = torch.ifft(output, 1) * output.size(-3)  # [batch, beta, alpha, complex]\n",
    "    output = output.view(*batch_size, 2 * b_out_m, 2 * b_out, 2)\n",
    "    return output\n",
    "\n",
    "\n",
    "class S2_fft_hh_real(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, b_out=None):  # pylint: disable=W\n",
    "        from s2cnn.utils.complex import as_complex\n",
    "        ctx.b_out = b_out\n",
    "        ctx.b_in = x.size(-1) // 2\n",
    "        return s2_fft_half_height(as_complex(x), b_out=ctx.b_out)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  # pylint: disable=W\n",
    "        return s2_ifft_half_height(grad_output, for_grad=True, b_out=ctx.b_in)[..., 0], None\n",
    "\n",
    "\n",
    "class S2_ifft_hh_real(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, b_out=None):  # pylint: disable=W\n",
    "        nspec = x.size(0)\n",
    "        ctx.b_out = b_out\n",
    "        ctx.b_in = round(nspec ** 0.5)\n",
    "        return s2_ifft_half_height(x, b_out=ctx.b_out)[..., 0]\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  # pylint: disable=W\n",
    "        from s2cnn.utils.complex import as_complex\n",
    "        return s2_fft_half_height(as_complex(grad_output), for_grad=True, b_out=ctx.b_in), None\n",
    "\n",
    "\n",
    "from s2cnn import S2Convolution\n",
    "\n",
    "class S2Convolution_hh(S2Convhh_olution):\n",
    "\n",
    "    def __init__(self, nfeature_in, nfeature_out, b_in, b_out, grid):\n",
    "        '''\n",
    "        :param nfeature_in: number of input fearures\n",
    "        :param nfeature_out: number of output features\n",
    "        :param b_in: input bandwidth (precision of the input SOFT grid)\n",
    "        :param b_out: output bandwidth\n",
    "        :param grid: points of the sphere defining the kernel, tuple of (alpha, beta)'s\n",
    "        '''\n",
    "        super(S2Convolution_hh, self).__init__(nfeature_in, nfeature_out, b_in, b_out, grid)\n",
    "\n",
    "    def forward(self, x):  # pylint: disable=W\n",
    "        '''\n",
    "        :x:      [batch, feature_in,  beta, alpha]\n",
    "        :return: [batch, feature_out, beta, alpha, gamma]\n",
    "        '''\n",
    "        assert x.size(1) == self.nfeature_in\n",
    "        assert x.size(2) == self.b_in\n",
    "        assert x.size(3) == 2 * self.b_in\n",
    "        x = S2_fft_hh_real.apply(x, self.b_out)  # [l * m, batch, feature_in, complex]\n",
    "        y = s2_rft(self.kernel * self.scaling, self.b_out, self.grid)  # [l * m, feature_in, feature_out, complex]\n",
    "\n",
    "        print('(x,y)', (x.shape,y.shape))\n",
    "\n",
    "        z = s2_mm(x, y)  # [l * m * n, batch, feature_out, complex]\n",
    "        z = SO3_ifft_real.apply(z)  # [batch, feature_out, beta, alpha, gamma]\n",
    "\n",
    "        z = z + self.bias\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SO3 rewrite (unfinished)\n",
    "- CUDA version not even started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def so3_rfft_half_height(x, for_grad=False, b_out=None):\n",
    "    '''\n",
    "    :param x: [..., beta, alpha, gamma]\n",
    "    :return: [l * m * n, ..., complex]\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "def so3_ifft_half_height(x, for_grad=False, b_out=None):\n",
    "    '''\n",
    "    :param x: [l * m * n, ..., complex]\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def so3_rifft_half_height(x, for_grad=False, b_out=None):\n",
    "    '''\n",
    "    :param x: [l * m * n, ..., complex]\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "class SO3_fft_hh_real(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, b_out=None):  # pylint: disable=W\n",
    "        ctx.b_out = b_out\n",
    "        ctx.b_in = x.size(-1) // 2\n",
    "        return so3_rfft_half_height(x, b_out=ctx.b_out)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output):  # pylint: disable=W\n",
    "        # ifft of grad_output is not necessarily real, therefore we cannot use rifft\n",
    "        return so3_ifft_half_height(grad_output, for_grad=True, b_out=self.b_in)[..., 0], None\n",
    "\n",
    "\n",
    "class SO3_ifft_hh_real(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, b_out=None):  # pylint: disable=W\n",
    "        nspec = x.size(0)\n",
    "        ctx.b_out = b_out\n",
    "        ctx.b_in = round((3 / 4 * nspec) ** (1 / 3))\n",
    "        return so3_rifft_half_height(x, b_out=ctx.b_out)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):  # pylint: disable=W\n",
    "        return so3_rfft_half_height(grad_output, for_grad=True, b_out=ctx.b_in), None\n",
    "\n",
    "\n",
    "from s2cnn import SO3Convolution\n",
    "\n",
    "class SO3Convolution_hh(SO3Convolution):\n",
    "    def __init__(self, nfeature_in, nfeature_out, b_in, b_out, grid):\n",
    "        '''\n",
    "        :param nfeature_in: number of input fearures\n",
    "        :param nfeature_out: number of output features\n",
    "        :param b_in: input bandwidth (precision of the input SOFT grid)\n",
    "        :param b_out: output bandwidth\n",
    "        :param grid: points of the SO(3) group defining the kernel, tuple of (alpha, beta, gamma)'s\n",
    "        '''\n",
    "        super(SO3Convolution_hh, self).__init__(nfeature_in, nfeature_out, b_in, b_out, grid)\n",
    "\n",
    "    def forward(self, x):  # pylint: disable=W\n",
    "        '''\n",
    "        :x:      [batch, feature_in,  beta, alpha, gamma]\n",
    "        :return: [batch, feature_out, beta, alpha, gamma]\n",
    "        '''\n",
    "        assert x.size(1) == self.nfeature_in\n",
    "        assert x.size(2) == 2 * self.b_in\n",
    "        assert x.size(3) == 2 * self.b_in\n",
    "        assert x.size(4) == 2 * self.b_in\n",
    "\n",
    "        x = SO3_fft_hh_real.apply(x, self.b_out)  # [l * m * n, batch, feature_in, complex]\n",
    "        y = so3_rft(self.kernel * self.scaling, self.b_out, self.grid)  # [l * m * n, feature_in, feature_out, complex]\n",
    "        assert x.size(0) == y.size(0)\n",
    "        assert x.size(2) == y.size(1)\n",
    "        z = so3_mm(x, y)  # [l * m * n, batch, feature_out, complex]\n",
    "        assert z.size(0) == x.size(0)\n",
    "        assert z.size(1) == x.size(1)\n",
    "        assert z.size(2) == y.size(2)\n",
    "        z = SO3_ifft_hh_real.apply(z)  # [batch, feature_out, beta, alpha, gamma]\n",
    "\n",
    "        z = z + self.bias\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test some FTs and IFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from s2cnn.soft.s2_fft import s2_ifft\n",
    "\n",
    "t = 736 # time index (in h)\n",
    "lvl = 0 # level index (indexing [500, 850] hPa)\n",
    "\n",
    "idcs63 = translate_idx(T=639, Tnew=63)\n",
    "ft = cohmp(T=639, Tnew=63, values=x639.t.values[t,lvl,:], idcs=idcs63)\n",
    "\n",
    "print('fourier transform shape: ', ft.shape)\n",
    "\n",
    "x = s2_ifft(torch.tensor(ft, dtype=torch.float32))\n",
    "plt.figure(figsize=(16,7))\n",
    "titles = ['real part', 'imaginary part']\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(x[0,:,:,i], aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title(titles[i])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "x = s2_ifft_half_height(torch.tensor(ft, dtype=torch.float32))\n",
    "plt.figure(figsize=(16,7))\n",
    "titles = ['real part', 'imaginary part']\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(x[0,:,:,i], aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title(titles[i])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "x = s2_ifft_half_height(s2_fft_half_height(x[:,:,:,:]))\n",
    "plt.figure(figsize=(16,7))\n",
    "titles = ['real part', 'imaginary part']\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(x[0,:,:,i], aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.title(titles[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plug into (custom) convolutional layer for S2CNN\n",
    "- S2Convolution() assumes input is already in grid-space, but here we got spherical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "import time\n",
    "\n",
    "from s2cnn.soft.so3_fft import SO3_ifft_real\n",
    "from s2cnn import s2_mm\n",
    "from s2cnn import s2_rft\n",
    "\n",
    "from s2cnn import s2_near_identity_grid\n",
    "from s2cnn import S2Convolution\n",
    "\n",
    "\n",
    "class FTConvolution(S2Convolution):\n",
    "    \n",
    "    def __init__(self, nfeature_in, nfeature_out, b_in, b_out, grid):\n",
    "        '''\n",
    "        :param nfeature_in: number of input fearures\n",
    "        :param nfeature_out: number of output features\n",
    "        :param b_in: input bandwidth (precision of the input SOFT grid)\n",
    "        :param b_out: output bandwidth\n",
    "        :param grid: points of the sphere defining the kernel, tuple of (alpha, beta)'s\n",
    "        '''\n",
    "        super(FTConvolution, self).__init__(nfeature_in, nfeature_out, b_in, b_out, grid)\n",
    "        \n",
    "    def forward(self, x):  # pylint: disable=W\n",
    "        ''' We rewrite the S2 convolution to start from x already Fourier-transformed\n",
    "        :x:      [b_in**2, batch, feature_in,  complex]\n",
    "        :return: [batch, feature_out, beta, alpha, gamma]\n",
    "        '''\n",
    "        assert x.size(0) == self.b_in**2\n",
    "        assert x.size(2) == self.nfeature_in\n",
    "        assert x.size(3) == 2\n",
    "\n",
    "        y = s2_rft(self.kernel * self.scaling, self.b_out, self.grid)  # [l * m, feature_in, feature_out, complex]\n",
    "\n",
    "        y = torch.as_tensor(y, dtype=torch.float32) # because reasons...\n",
    "                    \n",
    "        print('(x,y)', (x.shape, y.shape))\n",
    "            \n",
    "        z = s2_mm(x, y)  # [l * m * n, batch, feature_out, complex]\n",
    "        \n",
    "        print('z.shape', z.shape)\n",
    "        z = SO3_ifft_real.apply(z)  # [batch, feature_out, beta, alpha, gamma]\n",
    "        z = z + self.bias\n",
    "\n",
    "        return z\n",
    "\n",
    "# define convolutional layer \n",
    "\n",
    "T = 63\n",
    "b_in = T+1\n",
    "b_out = T+1\n",
    "grid_s2 = s2_near_identity_grid()\n",
    "        \n",
    "conv1 = FTConvolution(nfeature_in=2, nfeature_out=4, b_in=b_in, b_out=b_out, grid=grid_s2)\n",
    "\n",
    "# load and translate input data\n",
    "ts, lvls, ft = [0,1,2], [0,1], []\n",
    "idcs63 = translate_idx(T=639, Tnew=63)\n",
    "\n",
    "# stacking inputs (cohmp() not yet parallelized)\n",
    "for t in ts:\n",
    "    ft.append(np.concatenate(\n",
    "        [cohmp(T=639, Tnew=63, values=x639.t.values[t,lvl,:], idcs=idcs63) for lvl in lvls],\n",
    "        axis=1\n",
    "    ))\n",
    "ft = np.stack(ft, axis=1)\n",
    "print('ft.shape', ft.shape)\n",
    "              \n",
    "print('\\n beginning convolution ! \\n')\n",
    "t = time.time()\n",
    "out = conv1.forward(torch.tensor(ft, requires_grad=False, dtype=torch.float32))\n",
    "print(f'- finished in {time.time()-t}s -')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s2cnn.soft.so3_fft import SO3_fft_real, SO3_ifft_real\n",
    "x = SO3_fft_real.apply(torch.as_tensor(out, dtype=torch.float32), b_out)  # [l * m * n, batch, feature_in, complex]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plug into spherical CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from s2cnn import so3_near_identity_grid\n",
    "from s2cnn import s2_near_identity_grid\n",
    "\n",
    "from s2cnn import SO3Convolution\n",
    "from s2cnn import S2Convolution\n",
    "\n",
    "class S2ConvNet_original(nn.Module):\n",
    "\n",
    "    def __init__(self, f1=20, f2=40, f_output=1, b_in=64, b_l1=10, b_l2=6, nfeature_in=1):\n",
    "        super(S2ConvNet_original, self).__init__()\n",
    "\n",
    "        grid_s2 = s2_near_identity_grid()\n",
    "        grid_so3 = so3_near_identity_grid()\n",
    "\n",
    "        self.conv1 = S2Convolution_hh(\n",
    "            nfeature_in=nfeature_in,\n",
    "            nfeature_out=f1,\n",
    "            b_in=b_in,\n",
    "            b_out=b_l1,\n",
    "            grid=grid_s2)\n",
    "\n",
    "        self.conv2 = SO3Convolution(\n",
    "            nfeature_in=f1,\n",
    "            nfeature_out=f2,\n",
    "            b_in=b_l1,\n",
    "            b_out=b_l2,\n",
    "            grid=grid_so3)\n",
    "\n",
    "        self.out_layer = torch.nn.Conv2d(\n",
    "            in_channels=2 * b_l2, \n",
    "            out_channels=f_output, \n",
    "            kernel_size=(1,1))        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        print('x.shape', x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        print('x.shape', x.shape)\n",
    "        N, C = x.size(0), x.size(1)\n",
    "        x = x.view(N*C, x.size(2), x.size(3), x.size(4))\n",
    "        print('x.shape', x.shape)\n",
    "        x = self.out_layer(x)\n",
    "        print('x.shape', x.shape)\n",
    "        x = x.view(N, C, x.size(2), x.size(3))\n",
    "        print('x.shape', x.shape)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "model = S2ConvNet_original(f1=20, f2=1, f_output=1, b_in=T+1, b_l1=T+1, b_l2=(T+1)//2, nfeature_in=2)\n",
    "\n",
    "# stacking inputs (cohmp() not yet parallelized)\n",
    "ft = []\n",
    "for t in ts:\n",
    "    ft.append(np.concatenate(\n",
    "        [cohmp(T=639, Tnew=63, values=x639.t.values[t,lvl,:], idcs=idcs63) for lvl in lvls],\n",
    "        axis=1\n",
    "    ))\n",
    "ft = np.stack(ft, axis=1)\n",
    "print('ft.shape', ft.shape)\n",
    "x = s2_ifft_half_height(torch.tensor(ft, dtype=torch.float32))[:,:,:,:,0]\n",
    "\n",
    "out = model.forward(torch.tensor(x, requires_grad=False, dtype=torch.float32))\n",
    "\n",
    "x.shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out[2,0,:,:].detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# have a look into grids for kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def s2_soft_grid(b):\n",
    "    beta = (np.arange(2 * b) + 0.5) / (2 * b) * np.pi\n",
    "    alpha = np.linspace(start=0, stop=2 * np.pi, num=2 * b, endpoint=False)\n",
    "    B, A = np.meshgrid(beta, alpha, indexing='ij')\n",
    "    B = B.flatten()\n",
    "    A = A.flatten()\n",
    "    grid = np.stack((B, A), axis=1)\n",
    "    return tuple(tuple(ba) for ba in grid)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
