{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "datadir = '/gpfs/work/nonnenma/data/forecast_predictability/weatherbench/5_625deg/'\n",
    "res_dir = '/gpfs/work/nonnenma/results/forecast_predictability/weatherbench/5_625deg/'\n",
    "\n",
    "var_dict = {'geopotential': ('z', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'temperature': ('t', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'u_component_of_wind': ('u', [1,10,100,200,300,400,500,600,700,850,1000]), \n",
    "           'v_component_of_wind': ('v', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'specific_humidity': ('q', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'relative_humidity': ('r', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'vorticity': ('vo', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'potential_vorticity': ('pv', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'total_cloud_cover': ('tcc', [None]),\n",
    "           'total_precipitation': ('tp', [None]),\n",
    "           'toa_incident_solar_radiation': ('tisr', [None]),\n",
    "           'constants': ['lsm','orography','lat2d']\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xr.merge(\n",
    "[xr.open_mfdataset(f'{datadir}/{var}/*.nc', combine='by_coords')\n",
    " for var in var_dict.keys()],\n",
    "fill_value=0  # For the 'tisr' NaNs\n",
    ")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, dtype = x, np.float32\n",
    "data = []\n",
    "level_names = []\n",
    "generic_level = xr.DataArray([1], coords={'level': [1]}, dims=['level'])\n",
    "for long_var, params in var_dict.items():\n",
    "    if long_var == 'constants':\n",
    "        for var in params:\n",
    "            data.append(ds[var].expand_dims(\n",
    "                {'level': generic_level, 'time': ds.time}, (1, 0)\n",
    "            ).astype(dtype))\n",
    "            level_names.append(var)\n",
    "    else:\n",
    "        var, levels = params\n",
    "        try:\n",
    "            data.append(ds[var].sel(level=levels))\n",
    "            level_names += [f'{var}_{level}' for level in levels]\n",
    "        except ValueError:\n",
    "            data.append(ds[var].expand_dims({'level': generic_level}, 1))\n",
    "            level_names.append(var)\n",
    "data = xr.concat(data, 'level')  # .transpose('time', 'lat', 'lon', 'level')\n",
    "data['level_names'] = xr.DataArray(level_names, dims=['level'], coords={'level': data.level})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvalues = data.values\n",
    "allvalues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(datadir + '5_625deg_all', allvalues, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(datadir + '5_625deg_all_level_names', data['level_names'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.pytorch.Dataset import load_mean_std\n",
    "train_years = ('1979', '2015')\n",
    "\n",
    "mean, std, level, level_names = load_mean_std(res_dir, var_dict, train_years)\n",
    "for i in np.where([ln[-5:]=='_None' for ln in level_names])[0]: # some cleanup\n",
    "    level_names[i] = level_names[i][:-5] # discrepancy in code between code for single-level levels: '1' vs 'None'\n",
    "assert np.all( np.array(level_names) == data['level_names'])\n",
    "mean.shape, std.shape, len(level_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvalues -= mean.reshape(1,-1,1,1) # in-place feels dangerous, \n",
    "allvalues /= std.reshape(1,-1,1,1)  # but allvalues hardly fits into memory twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(datadir + '5_625deg_all_zscored', allvalues, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
