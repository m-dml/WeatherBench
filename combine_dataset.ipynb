{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "datadir = '/gpfs/work/nonnenma/data/forecast_predictability/weatherbench/5_625deg/'\n",
    "res_dir = '/gpfs/work/nonnenma/results/forecast_predictability/weatherbench/5_625deg/'\n",
    "\n",
    "var_dict = {'geopotential': ('z', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'temperature': ('t', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'u_component_of_wind': ('u', [1,10,100,200,300,400,500,600,700,850,1000]), \n",
    "           'v_component_of_wind': ('v', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'specific_humidity': ('q', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'relative_humidity': ('r', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'vorticity': ('vo', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'potential_vorticity': ('pv', [1,10,100,200,300,400,500,600,700,850,1000]),\n",
    "           'total_cloud_cover': ('tcc', [None]),\n",
    "           'total_precipitation': ('tp', [None]),\n",
    "           'toa_incident_solar_radiation': ('tisr', [None]),\n",
    "           'rel_time': ('time_map', [None]),\n",
    "           'constants': ['lsm','orography','lat2d']\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:    (lat: 32, level: 11, lon: 64, time: 350640)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 1979-01-01 ... 2018-12-31T23:00:00\n",
       "  * lat        (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon        (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * level      (level) int32 1 10 100 200 300 400 500 600 700 850 1000\n",
       "Data variables:\n",
       "    z          (time, level, lat, lon) float32 dask.array&lt;chunksize=(8760, 11, 32, 64), meta=np.ndarray&gt;\n",
       "    t          (time, level, lat, lon) float32 dask.array&lt;chunksize=(8760, 11, 32, 64), meta=np.ndarray&gt;\n",
       "    u          (time, level, lat, lon) float32 dask.array&lt;chunksize=(8760, 11, 32, 64), meta=np.ndarray&gt;\n",
       "    v          (time, level, lat, lon) float32 dask.array&lt;chunksize=(8760, 11, 32, 64), meta=np.ndarray&gt;\n",
       "    q          (time, level, lat, lon) float32 dask.array&lt;chunksize=(8760, 11, 32, 64), meta=np.ndarray&gt;\n",
       "    r          (time, level, lat, lon) float32 dask.array&lt;chunksize=(8760, 11, 32, 64), meta=np.ndarray&gt;\n",
       "    vo         (time, level, lat, lon) float32 dask.array&lt;chunksize=(8760, 11, 32, 64), meta=np.ndarray&gt;\n",
       "    pv         (time, level, lat, lon) float32 dask.array&lt;chunksize=(8760, 11, 32, 64), meta=np.ndarray&gt;\n",
       "    tcc        (time, lat, lon) float32 dask.array&lt;chunksize=(8760, 32, 64), meta=np.ndarray&gt;\n",
       "    tp         (time, lat, lon) float32 dask.array&lt;chunksize=(8760, 32, 64), meta=np.ndarray&gt;\n",
       "    tisr       (time, lat, lon) float32 dask.array&lt;chunksize=(8760, 32, 64), meta=np.ndarray&gt;\n",
       "    time_map   (time, lat, lon) float32 dask.array&lt;chunksize=(350640, 32, 64), meta=np.ndarray&gt;\n",
       "    orography  (lat, lon) float32 dask.array&lt;chunksize=(32, 64), meta=np.ndarray&gt;\n",
       "    lsm        (lat, lon) float32 dask.array&lt;chunksize=(32, 64), meta=np.ndarray&gt;\n",
       "    slt        (lat, lon) float32 dask.array&lt;chunksize=(32, 64), meta=np.ndarray&gt;\n",
       "    lat2d      (lat, lon) float64 dask.array&lt;chunksize=(32, 64), meta=np.ndarray&gt;\n",
       "    lon2d      (lat, lon) float64 dask.array&lt;chunksize=(32, 64), meta=np.ndarray&gt;</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (lat: 32, level: 11, lon: 64, time: 350640)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 1979-01-01 ... 2018-12-31T23:00:00\n",
       "  * lat        (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon        (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * level      (level) int32 1 10 100 200 300 400 500 600 700 850 1000\n",
       "Data variables:\n",
       "    z          (time, level, lat, lon) float32 dask.array<chunksize=(8760, 11, 32, 64), meta=np.ndarray>\n",
       "    t          (time, level, lat, lon) float32 dask.array<chunksize=(8760, 11, 32, 64), meta=np.ndarray>\n",
       "    u          (time, level, lat, lon) float32 dask.array<chunksize=(8760, 11, 32, 64), meta=np.ndarray>\n",
       "    v          (time, level, lat, lon) float32 dask.array<chunksize=(8760, 11, 32, 64), meta=np.ndarray>\n",
       "    q          (time, level, lat, lon) float32 dask.array<chunksize=(8760, 11, 32, 64), meta=np.ndarray>\n",
       "    r          (time, level, lat, lon) float32 dask.array<chunksize=(8760, 11, 32, 64), meta=np.ndarray>\n",
       "    vo         (time, level, lat, lon) float32 dask.array<chunksize=(8760, 11, 32, 64), meta=np.ndarray>\n",
       "    pv         (time, level, lat, lon) float32 dask.array<chunksize=(8760, 11, 32, 64), meta=np.ndarray>\n",
       "    tcc        (time, lat, lon) float32 dask.array<chunksize=(8760, 32, 64), meta=np.ndarray>\n",
       "    tp         (time, lat, lon) float32 dask.array<chunksize=(8760, 32, 64), meta=np.ndarray>\n",
       "    tisr       (time, lat, lon) float32 dask.array<chunksize=(8760, 32, 64), meta=np.ndarray>\n",
       "    time_map   (time, lat, lon) float32 dask.array<chunksize=(350640, 32, 64), meta=np.ndarray>\n",
       "    orography  (lat, lon) float32 dask.array<chunksize=(32, 64), meta=np.ndarray>\n",
       "    lsm        (lat, lon) float32 dask.array<chunksize=(32, 64), meta=np.ndarray>\n",
       "    slt        (lat, lon) float32 dask.array<chunksize=(32, 64), meta=np.ndarray>\n",
       "    lat2d      (lat, lon) float64 dask.array<chunksize=(32, 64), meta=np.ndarray>\n",
       "    lon2d      (lat, lon) float64 dask.array<chunksize=(32, 64), meta=np.ndarray>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xr.merge(\n",
    "[xr.open_mfdataset(f'{datadir}/{var}/*.nc', combine='by_coords')\n",
    " for var in var_dict.keys()],\n",
    "fill_value=0  # For the 'tisr' NaNs\n",
    ")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# create and store maps of relative time in hours from 1979-01-01T00:00:00.00\n",
    "all_time = np.asarray(np.arange(x.time.size).reshape(-1,1,1) * np.ones((x.time.size,32,64)), dtype=np.float32)\n",
    "xtime = xr.DataArray(\n",
    "        all_time, \n",
    "        name='time_map',\n",
    "        dims=['time', 'lat', 'lon'], \n",
    "        coords={'time': x.time, 'lon': x.lon, 'lat': x.lat}) \n",
    "xtime.to_netcdf(f'{datadir}/rel_time/rel_time_5.625deg.nc')\n",
    "\n",
    "# compute and store means and stds for later z-scoring\n",
    "rel_time_mean = xtime.mean(('time', 'lat', 'lon')).compute()\n",
    "rel_time_std = xtime.std(('time', 'lat', 'lon')).compute()\n",
    "generic_level = xr.DataArray([1], coords={'level': [1]}, dims=['level'])\n",
    "rel_time_mean = rel_time_mean.expand_dims({'level': generic_level}, 0)\n",
    "rel_time_std = rel_time_std.expand_dims({'level': generic_level}, 0)\n",
    "\n",
    "train_years = ('1979', '2015')\n",
    "var = 'rel_time'\n",
    "rel_time_mean.to_netcdf(f'{res_dir}/{var}/mean_{train_years[0]}_{train_years[1]}.nc')\n",
    "rel_time_std.to_netcdf(f'{res_dir}/{var}/std_{train_years[0]}_{train_years[1]}.nc')\n",
    "xtime\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, dtype = x, np.float32\n",
    "data = []\n",
    "level_names = []\n",
    "generic_level = xr.DataArray([1], coords={'level': [1]}, dims=['level'])\n",
    "for long_var, params in var_dict.items():\n",
    "    if long_var == 'constants':\n",
    "        for var in params:\n",
    "            data.append(ds[var].expand_dims(\n",
    "                {'level': generic_level, 'time': ds.time}, (1, 0)\n",
    "            ).astype(dtype))\n",
    "            level_names.append(var)\n",
    "    else:\n",
    "        var, levels = params\n",
    "        try:\n",
    "            data.append(ds[var].sel(level=levels))\n",
    "            level_names += [f'{var}_{level}' for level in levels]\n",
    "        except ValueError:\n",
    "            data.append(ds[var].expand_dims({'level': generic_level}, 1))\n",
    "            level_names.append(var)\n",
    "data = xr.concat(data, 'level')  # .transpose('time', 'lat', 'lon', 'level')\n",
    "data['level_names'] = xr.DataArray(level_names, dims=['level'], coords={'level': data.level})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;z&#x27; (time: 350640, level: 95, lat: 32, lon: 64)&gt;\n",
       "dask.array&lt;concatenate, shape=(350640, 95, 32, 64), dtype=float32, chunksize=(8784, 11, 32, 64), chunktype=numpy.ndarray&gt;\n",
       "Coordinates:\n",
       "  * time         (time) datetime64[ns] 1979-01-01 ... 2018-12-31T23:00:00\n",
       "  * lat          (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon          (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * level        (level) int64 1 10 100 200 300 400 500 600 ... 1 1 1 1 1 1 1\n",
       "    level_names  (level) &lt;U9 &#x27;z_1&#x27; &#x27;z_10&#x27; &#x27;z_100&#x27; ... &#x27;lsm&#x27; &#x27;orography&#x27; &#x27;lat2d&#x27;\n",
       "Attributes:\n",
       "    units:          m**2 s**-2\n",
       "    long_name:      Geopotential\n",
       "    standard_name:  geopotential</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'z' (time: 350640, level: 95, lat: 32, lon: 64)>\n",
       "dask.array<concatenate, shape=(350640, 95, 32, 64), dtype=float32, chunksize=(8784, 11, 32, 64), chunktype=numpy.ndarray>\n",
       "Coordinates:\n",
       "  * time         (time) datetime64[ns] 1979-01-01 ... 2018-12-31T23:00:00\n",
       "  * lat          (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon          (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * level        (level) int64 1 10 100 200 300 400 500 600 ... 1 1 1 1 1 1 1\n",
       "    level_names  (level) <U9 'z_1' 'z_10' 'z_100' ... 'lsm' 'orography' 'lat2d'\n",
       "Attributes:\n",
       "    units:          m**2 s**-2\n",
       "    long_name:      Geopotential\n",
       "    standard_name:  geopotential"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350640, 95, 32, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvalues = data.values\n",
    "allvalues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(datadir + '5_625deg_all', allvalues, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(datadir + '5_625deg_all_level_names', data['level_names'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95,), (95,), 95)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.pytorch.Dataset import load_mean_std\n",
    "train_years = ('1979', '2015')\n",
    "\n",
    "mean, std, level, level_names = load_mean_std(res_dir, var_dict, train_years)\n",
    "for i in np.where([ln[-5:]=='_None' for ln in level_names])[0]: # some cleanup\n",
    "    level_names[i] = level_names[i][:-5] # discrepancy in code between code for single-level levels: '1' vs 'None'\n",
    "assert np.all( np.array(level_names) == data['level_names'])\n",
    "mean.shape, std.shape, len(level_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvalues -= mean.reshape(1,-1,1,1) # in-place feels dangerous, \n",
    "allvalues /= std.reshape(1,-1,1,1)  # but allvalues hardly fits into memory twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(datadir + '5_625deg_all_zscored', allvalues, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
