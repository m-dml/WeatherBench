{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# dev\n",
    "- reimplementing the 'Quickstart' notebook from S. Rasp for training in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available\n",
      "Loading means and standard deviations from disk\n",
      "n_channels 23\n",
      "model filename 23D_fcsimpleResnet_3d_pytorch_lrdecay_weightdecay_normed_test.pt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "from src.pytorch.Dataset import Dataset\n",
    "from src.pytorch.util import init_torch_device\n",
    "\n",
    "device = init_torch_device()\n",
    "\n",
    "datadir = '/gpfs/work/nonnenma/data/forecast_predictability/weatherbench/5_625deg/'\n",
    "res_dir = '/gpfs/work/nonnenma/results/forecast_predictability/weatherbench/5_625deg/'\n",
    "\n",
    "model_name = 'simpleResnet' # 'simpleResnet', 'tvfcnResnet50', 'cnnbn', 'Unetbn'\n",
    "\n",
    "lead_time = 3*24\n",
    "batch_size = 32\n",
    "\n",
    "train_years = ('1979', '2015')\n",
    "\n",
    "var_dict = {'geopotential': ('z', [100, 200, 500, 850, 1000]),\n",
    "           'temperature': ('t', [100, 200, 500, 850, 1000]),\n",
    "           'u_component_of_wind': ('u', [100, 200, 500, 850, 1000]), \n",
    "           'v_component_of_wind': ('v', [100, 200, 500, 850, 1000]),\n",
    "           'constants': ['lsm','orography','lat2d']\n",
    "           }\n",
    "target_vars = ['geopotential', 'temperature']\n",
    "target_levels = [500, 850]\n",
    "\n",
    "x = xr.merge(\n",
    "[xr.open_mfdataset(f'{datadir}/{var}/*.nc', combine='by_coords')\n",
    " for var in var_dict.keys()],\n",
    "fill_value=0  # For the 'tisr' NaNs\n",
    ")\n",
    "x = x.chunk({'time' : np.sum(x.chunks['time']), 'lat' : x.chunks['lat'], 'lon': x.chunks['lon']})\n",
    "\n",
    "dg_train = Dataset(x.sel(time=slice(train_years[0], train_years[1])), var_dict, lead_time, \n",
    "                   normalize=True, norm_subsample=1, res_dir=res_dir, train_years=train_years,\n",
    "                   target_vars=target_vars, target_levels=target_levels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dg_train,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True)\n",
    "\n",
    "dg_validation =  Dataset(x.sel(time=slice('2016', '2016')), var_dict, lead_time,\n",
    "                        mean=dg_train.mean, std=dg_train.std, normalize=True, randomize_order=False,\n",
    "                        target_vars=target_vars, target_levels=target_levels)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dg_validation,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False)\n",
    "\n",
    "n_channels = len(dg_train.data.level.level)\n",
    "print('n_channels', n_channels)\n",
    "\n",
    "#model_fn = f'{n_channels}D_fc{model_name}_{lead_time//24}d_pytorch.pt' # file name for saving/loading prediction model\n",
    "model_fn = f'{n_channels}D_fc{model_name}_{lead_time//24}d_pytorch_lrdecay_weightdecay_normed_test.pt' # file name for saving/loading prediction model\n",
    "print('model filename', model_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check I/O speed on single (empty) epoch\n",
    "for batch in train_loader:\n",
    "    inputs, targets = batch[0].to(device), batch[1].to(device)\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.pytorch.util import named_network\n",
    "model, model_forward = named_network(model_name, n_channels, len(target_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.pytorch.train import train_model\n",
    "\n",
    "train_again = False\n",
    "if train_again:\n",
    "    training_outputs = train_model(model, train_loader, validation_loader, device, model_forward,\n",
    "                    lr=5e-4, lr_min=1e-5, lr_decay=0.2, weight_decay=1e-5,\n",
    "                    max_epochs=200, max_patience=20, max_lr_patience=5, eval_every=2000,\n",
    "                    verbose=True, save_dir=res_dir + model_fn)\n",
    "\n",
    "# if skip training, load model from disk\n",
    "else:\n",
    "    model.load_state_dict(torch.load(res_dir + model_fn, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pytorch.train import calc_val_loss\n",
    "\n",
    "validation_loss = calc_val_loss(validation_loader, model_forward, device)\n",
    "validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.pytorch.train_nn import create_predictions\n",
    "from src.score import compute_weighted_rmse, load_test_data\n",
    "\n",
    "dg_test =  Dataset(x.sel(time=slice('2017', '2018')),\n",
    "                   var_dict,\n",
    "                   lead_time,\n",
    "                   mean=dg_train.mean, # make sure that model was trained \n",
    "                   std=dg_train.std,   # with same data as in dg_train, \n",
    "                   normalize=True,     # or else normalization is off!\n",
    "                   randomize_order=False,\n",
    "                   target_vars=target_vars, \n",
    "                   target_levels=target_levels)\n",
    "\n",
    "preds = create_predictions(model,\n",
    "                           dg_test,\n",
    "                           var_dict={'z' : None, 't' : None},\n",
    "                           batch_size=100,\n",
    "                           model_forward=model_forward,\n",
    "                           verbose=True)\n",
    "\n",
    "z500_test = load_test_data(f'{datadir}geopotential_500/', 'z')\n",
    "t850_test = load_test_data(f'{datadir}temperature_850/', 't')\n",
    "rmse_z = compute_weighted_rmse(preds.z, z500_test.isel(time=slice(lead_time, None))).load()\n",
    "rmse_t = compute_weighted_rmse(preds.t, t850_test.isel(time=slice(lead_time, None))).load()\n",
    "print('RMSE z', rmse_z.values); print('RMSE t', rmse_t.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dg = dg_test\n",
    "\n",
    "# variable names for display in figure\n",
    "var_names = {'geopotential' : 'geopotential at 500hPa', \n",
    "             'temperature' : 'temperature at 850hPa'}\n",
    "\n",
    "# pick time stamps to visualize\n",
    "idx = [2000] # index relative to start time of dataset !\n",
    "\n",
    "for i in idx:\n",
    "    pre = dg[[i]][0]\n",
    "    post = dg[[i]][1]\n",
    "    # predict for single time stamp\n",
    "    pred = model_forward(torch.tensor(pre,requires_grad=False).to(device)).detach().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(16,6))\n",
    "    for j in range(2):\n",
    "        plt.subplot(1,2,j+1)\n",
    "\n",
    "        # top: current state, middle: model-predicted future state, bottom: future state\n",
    "        j_ = dg._target_idx[j] # index for dg object in case first two dimensions not Z500, T850\n",
    "        plt.imshow(np.vstack((post[0,j,:,:], pred[0,j,:,:], pre[0,j_,:,:])))\n",
    "\n",
    "        plt.plot([0.5, pred.shape[3]+.5], (1*pred.shape[2]-0.5)*np.ones(2), 'k', linewidth=1.5)\n",
    "        plt.plot([0.5, pred.shape[3]+.5], (2*pred.shape[2]-0.5)*np.ones(2), 'k', linewidth=1.5)\n",
    "        plt.yticks([pred.shape[2]//2, 3*pred.shape[2]//2, 5*pred.shape[2]//2],\n",
    "                   [f'+{lead_time}h true', f'+{lead_time}h est.', 'state'])\n",
    "        plt.axis([-0.5, pred.shape[3]-0.5, -0.5, 3*pred.shape[2]-0.5])\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(var_names[list(dg.var_dict.keys())[j]])\n",
    "        plt.title(dg.data.time.isel(time=i).values)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE per pixel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RMSEs_z = np.sqrt(np.mean((preds[:,0,:,:] - z500_test.isel(time=slice(lead_time, None)))**2, axis=0))\n",
    "RMSEs_t = np.sqrt(np.mean((preds[:,1,:,:] - t850_test.isel(time=slice(lead_time, None)))**2, axis=0))\n",
    "\n",
    "\n",
    "weights_lat = np.cos(np.deg2rad(z500_test.lat))\n",
    "weights_lat /= weights_lat.mean()\n",
    "\n",
    "wRMSEs_z = np.sqrt(\n",
    "    np.mean( ((preds[:,0,:,:] - z500_test.isel(time=slice(lead_time, None)))**2)*weights_lat, \n",
    "            axis=0))\n",
    "wRMSEs_t = np.sqrt(\n",
    "    np.mean( ((preds[:,1,:,:] - t850_test.isel(time=slice(lead_time, None)))**2)*weights_lat, \n",
    "            axis=0))\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(RMSEs_z)\n",
    "plt.title('RMSEs Z500')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(RMSEs_t)\n",
    "plt.title('RMSEs T850')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(wRMSEs_z)\n",
    "plt.title('weighted RMSEs Z500')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(wRMSEs_t)\n",
    "plt.title('weighted RMSEs T850')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSEs per time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RMSEs_z = np.sqrt(np.mean((preds[:,0,:,:] - z500_test.isel(time=slice(lead_time, None)))**2, axis=[1,2]))\n",
    "RMSEs_t = np.sqrt(np.mean((preds[:,1,:,:] - t850_test.isel(time=slice(lead_time, None)))**2, axis=[1,2]))\n",
    "\n",
    "\n",
    "weights_lat = np.cos(np.deg2rad(z500_test.lat))\n",
    "weights_lat /= weights_lat.mean()\n",
    "\n",
    "wRMSEs_z = np.sqrt(\n",
    "    np.mean( ((preds[:,0,:,:] - z500_test.isel(time=slice(lead_time, None)))**2)*weights_lat, \n",
    "            axis=[1,2]))\n",
    "wRMSEs_t = np.sqrt(\n",
    "    np.mean( ((preds[:,1,:,:] - t850_test.isel(time=slice(lead_time, None)))**2)*weights_lat, \n",
    "            axis=[1,2]))\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(RMSEs_z)\n",
    "plt.title('RMSEs Z500')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(RMSEs_t)\n",
    "plt.title('RMSEs T850')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(wRMSEs_z)\n",
    "plt.title('weighted RMSEs Z500')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(wRMSEs_t)\n",
    "plt.title('weighted RMSEs T850')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
