{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# dev\n",
    "- reimplementing the 'Quickstart' notebook from S. Rasp for training in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from src.pytorch.util import init_torch_device\n",
    "\n",
    "device = init_torch_device()\n",
    "\n",
    "datadir = '/gpfs/work/nonnenma/data/forecast_predictability/weatherbench/5_625deg/'\n",
    "res_dir = '/gpfs/work/nonnenma/results/forecast_predictability/weatherbench/5_625deg/'\n",
    "\n",
    "lead_time = 3*24\n",
    "batch_size = 32\n",
    "\n",
    "train_years = ('1979', '2015')\n",
    "validation_years = ('2016', '2016')\n",
    "test_years = ('2017', '2018')\n",
    "\n",
    "var_dict = {'geopotential': ('z', [100, 200, 500, 850, 1000]),\n",
    "           'temperature': ('t', [100, 200, 500, 850, 1000]),\n",
    "           'u_component_of_wind': ('u', [100, 200, 500, 850, 1000]), \n",
    "           'v_component_of_wind': ('v', [100, 200, 500, 850, 1000]),\n",
    "           'constants': ['lsm','orography','lat2d']\n",
    "           }\n",
    "\n",
    "target_var_dict = {'geopotential': 500, 'temperature': 850}\n",
    "\n",
    "model_name = 'ConvLSTM' # 'simpleResnet', 'tvfcnResnet50', 'cnnbn', 'Unetbn'\n",
    "\n",
    "#filters = [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]\n",
    "#kernel_sizes = [7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "#past_times = [-6, -12]\n",
    "\n",
    "filters = [128, 64, 64, 2]\n",
    "kernel_sizes = [3, 3, 3, 3]\n",
    "past_times = [-3, -6, -9, -12, -15, -18, -21, -24, -27, -30, -33, -36]\n",
    "\n",
    "dropout_rate = 0.1\n",
    "past_times_own_axis = True\n",
    "\n",
    "verbose = True\n",
    "loss_fun = 'mse'\n",
    "\n",
    "mmap_mode = None #'r'\n",
    "\n",
    "datadirdg = '/gpfs/work/greenber/'\n",
    "filedir = datadir + '5_625deg_all_zscored.npy'\n",
    "leveldir = datadir + '5_625deg_all_level_names.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pytorch.util import load_data\n",
    "from src.pytorch.Dataset import collate_fn_memmap, load_mean_std\n",
    "\n",
    "# load data\n",
    "dg_train, dg_validation, dg_test, dg_meta = load_data(\n",
    "    var_dict=var_dict, lead_time=lead_time,\n",
    "    train_years=(train_years[0], train_years[1]), \n",
    "    validation_years=(validation_years[0], validation_years[1]), \n",
    "    test_years=(test_years[0], test_years[1]),\n",
    "    target_var_dict=target_var_dict, datadir=datadir, \n",
    "    mmap_mode=mmap_mode, past_times=past_times, past_times_own_axis=past_times_own_axis\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return collate_fn_memmap(batch, dg_train, past_times_own_axis=past_times_own_axis)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dg_validation, batch_size=batch_size, drop_last=False\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dg_train, batch_size=batch_size, collate_fn=collate_fn, drop_last=True,\n",
    "    num_workers=0 #int(train_years[1]) - int(train_years[0]) + 1\n",
    ")\n",
    "\n",
    "n_channels = len(dg_train._var_idx) if past_times_own_axis else len(dg_train._var_idx) * len(dg_train.past_times)\n",
    "print('n_channels', n_channels)\n",
    "\n",
    "model_fn = f'{n_channels}D_fc{model_name}_{lead_time//24}d_pytorch.pt' # file name for saving/loading prediction model\n",
    "#model_fn = f'{n_channels}D_fc{model_name}_{lead_time//24}d_pytorch_lrdecay_weightdecay_normed_test2.pt' # file name for saving/loading prediction model\n",
    "print('model filename', model_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_steps = 200\n",
    "print_every = 10\n",
    "\n",
    "import time\n",
    "def do_dummy_epoch(train_loader, t = None):\n",
    "    # check I/O speed on single (empty) epoch\n",
    "    num_steps = 1\n",
    "    t = time.time() if t is None else t\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = batch[0].to(device), batch[1].to(device)\n",
    "        if np.mod(num_steps, print_every) == 0 or num_steps == 1:\n",
    "            print(f\"- batch #{num_steps}, time: {'{0:.2f}'.format(time.time() - t)}\")\n",
    "            print(inputs.shape, targets.shape)\n",
    "        num_steps +=1\n",
    "        if num_steps > max_steps:\n",
    "            #out = inputs.numpy()\n",
    "            break\n",
    "    #return out\n",
    "\n",
    "t = time.time()\n",
    "do_dummy_epoch(train_loader, t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ConvLSTM' # 'simpleResnet', 'tvfcnResnet50', 'cnnbn', 'Unetbn'\n",
    "\n",
    "#filters = [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]\n",
    "#kernel_sizes = [7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "#past_times = [-6, -12]\n",
    "\n",
    "filters = [128, 64, 64, 2]\n",
    "kernel_sizes = [3, 3, 3, 3]\n",
    "past_times = [-3, -6, -9, -12, -15, -18, -21, -24, -27, -30, -33, -36]\n",
    "\n",
    "past_times_own_axis = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from src.pytorch.util import named_network\n",
    "model, model_forward = named_network(model_name, n_channels, len(target_var_dict), \n",
    "                                     filters=filters, kernel_sizes=kernel_sizes)\n",
    "\"\"\"\n",
    "from src.pytorch.util import named_network\n",
    "\n",
    "model, model_forward = named_network(model_name, n_channels, len(target_var_dict), \n",
    "                                     kernel_sizes=kernel_sizes, filters=filters, dropout_rate=dropout_rate)\n",
    "\n",
    "print('total #parameters: ', np.sum([np.prod(item.shape) for item in model.state_dict().values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = 'models/convlstm_test/convlstm_test_23D_fcConvLSTM_72h.pt'\n",
    "#model_fn = 'models/multi_delay_test/multi_delay_test_69D_fcsimpleResnet_72h.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.pytorch.train import train_model, loss_function\n",
    "\n",
    "train_again = False\n",
    "if train_again:\n",
    "    loss_fun = loss_function(loss_fun)\n",
    "    training_outputs = train_model(model, train_loader, validation_loader, device, model_forward,\n",
    "                    loss_fun=loss_fun, lr=5e-4, lr_min=1e-5, lr_decay=0.2, weight_decay=1e-5,\n",
    "                    max_epochs=200, max_patience=20, max_lr_patience=5, eval_every=2000,\n",
    "                    verbose=True, save_dir=res_dir + model_fn)\n",
    "\n",
    "# if skip training, load model from disk\n",
    "else:\n",
    "    model.load_state_dict(torch.load(res_dir + model_fn, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.score import compute_weighted_rmse, load_test_data\n",
    "z500_test = load_test_data(f'{datadir}geopotential_500/', 'z')\n",
    "t850_test = load_test_data(f'{datadir}temperature_850/', 't')\n",
    "z500_test.isel(time=slice(lead_time+dg_test.max_input_lag, None)).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.pytorch.train import calc_val_loss\n",
    "#print('validation loss:', calc_val_loss(validation_loader, model_forward, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.pytorch.train_nn import create_predictions\n",
    "from src.score import compute_weighted_rmse, load_test_data\n",
    "\n",
    "mean, std, _, _ = load_mean_std(res_dir, {'geopotential': ['z', [500]], 'temperature': ['t', [850]]}, train_years)   \n",
    "valid_test_time = dg_meta['time'].sel(time=slice(test_years[0], test_years[1]))\n",
    "dg_meta['valid_time'] = valid_test_time.isel(time=slice(dg_test.lead_time+dg_test.max_input_lag, None)).time\n",
    "preds = create_predictions(model,\n",
    "                           dg_test,\n",
    "                           var_dict={'z' : None, 't' : None},\n",
    "                           batch_size=100,\n",
    "                           model_forward=model_forward,\n",
    "                           verbose=True,\n",
    "                           past_times_own_axis=past_times_own_axis,\n",
    "                           mean=mean, \n",
    "                           std=std,\n",
    "                           dg_meta=dg_meta)\n",
    "\n",
    "z500_test = load_test_data(f'{datadir}geopotential_500/', 'z')\n",
    "t850_test = load_test_data(f'{datadir}temperature_850/', 't')\n",
    "rmse_z = compute_weighted_rmse(preds.z, z500_test.isel(time=slice(lead_time+dg_test.max_input_lag, None))).load()\n",
    "rmse_t = compute_weighted_rmse(preds.t, t850_test.isel(time=slice(lead_time+dg_test.max_input_lag, None))).load()\n",
    "print('RMSE z', rmse_z.values); print('RMSE t', rmse_t.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dg = dg_test\n",
    "\n",
    "# variable names for display in figure\n",
    "var_names = {'geopotential' : 'geopotential at 500hPa', \n",
    "             'temperature' : 'temperature at 850hPa'}\n",
    "\n",
    "# pick time stamps to visualize\n",
    "idx = [dg_test.start+100] # index relative to start time of dataset !\n",
    "\n",
    "for i in idx:\n",
    "    pre = dg[[i]][0]\n",
    "    if past_times_own_axis:\n",
    "        pre = pre.reshape((len(dg._past_idx), 1,  len(dg._var_idx), *pre.shape[2:])).transpose(1,0,2,3,4)\n",
    "    post = dg[[i]][1]\n",
    "    # predict for single time stamp\n",
    "    pred = model_forward(torch.tensor(pre,requires_grad=False).to(device)).detach().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(16,6))\n",
    "    for j in range(2):\n",
    "        plt.subplot(1,2,j+1)\n",
    "\n",
    "        # top: current state, middle: model-predicted future state, bottom: future state\n",
    "        j_ = dg._target_idx[j] # index for dg object in case first two dimensions not Z500, T850\n",
    "        plt.imshow(np.vstack((post[0,j,:,:], pred[0,j,:,:], pre[0,-1,j_,:,:])))\n",
    "\n",
    "        plt.plot([0.5, pred.shape[3]+.5], (1*pred.shape[2]-0.5)*np.ones(2), 'k', linewidth=1.5)\n",
    "        plt.plot([0.5, pred.shape[3]+.5], (2*pred.shape[2]-0.5)*np.ones(2), 'k', linewidth=1.5)\n",
    "        plt.yticks([pred.shape[2]//2, 3*pred.shape[2]//2, 5*pred.shape[2]//2],\n",
    "                   [f'+{lead_time}h true', f'+{lead_time}h est.', 'state'])\n",
    "        plt.axis([-0.5, pred.shape[3]-0.5, -0.5, 3*pred.shape[2]-0.5])\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(var_names[list(dg.var_dict.keys())[j]])\n",
    "        #plt.title(dg.data.time.isel(time=i).values)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dg = dg_test\n",
    "\n",
    "# variable names for display in figure\n",
    "var_names = {'geopotential' : 'geopotential at 500hPa', \n",
    "             'temperature' : 'temperature at 850hPa'}\n",
    "\n",
    "# pick time stamps to visualize\n",
    "idx = [2000] # index relative to start time of dataset !\n",
    "\n",
    "for i in idx:\n",
    "    pre = dg[[i]][0]\n",
    "    post = dg[[i]][1]\n",
    "    # predict for single time stamp\n",
    "    pred = model_forward(torch.tensor(pre,requires_grad=False).to(device)).detach().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(16,6))\n",
    "    for j in range(2):\n",
    "        plt.subplot(1,2,j+1)\n",
    "\n",
    "        # top: current state, middle: model-predicted future state, bottom: future state\n",
    "        j_ = dg._target_idx[j] # index for dg object in case first two dimensions not Z500, T850\n",
    "        plt.imshow(np.vstack((post[0,j,:,:], pred[0,j,:,:], pre[0,j_,:,:])))\n",
    "\n",
    "        plt.plot([0.5, pred.shape[3]+.5], (1*pred.shape[2]-0.5)*np.ones(2), 'k', linewidth=1.5)\n",
    "        plt.plot([0.5, pred.shape[3]+.5], (2*pred.shape[2]-0.5)*np.ones(2), 'k', linewidth=1.5)\n",
    "        plt.yticks([pred.shape[2]//2, 3*pred.shape[2]//2, 5*pred.shape[2]//2],\n",
    "                   [f'+{lead_time}h true', f'+{lead_time}h est.', 'state'])\n",
    "        plt.axis([-0.5, pred.shape[3]-0.5, -0.5, 3*pred.shape[2]-0.5])\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(var_names[list(dg.var_dict.keys())[j]])\n",
    "        plt.title(dg.data.time.isel(time=i).values)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model survery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "exp_ids = ['resnet_baseline', 'resnet_baseline_no_L2',  'resnet_latmse', 'multi_delay_test']\n",
    "def find_weights(fn):\n",
    "    return fn[-4:] == 'h.pt'\n",
    "dims = [23, 23, 23, 33]\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "for exp_id, dim in zip(exp_ids, dims):\n",
    "    save_dir = res_dir + 'models/' + exp_id + '/'\n",
    "\n",
    "    model_fn = list(filter(find_weights, os.listdir(save_dir)))[0]\n",
    "    lead_time = model_fn[-6:-4]\n",
    "    training_outputs = np.load(save_dir + '_training_outputs' + '.npy', allow_pickle=True)[()]\n",
    "\n",
    "    try:\n",
    "        training_loss, validation_loss = training_outputs['training_loss'], training_outputs['validation_loss']\n",
    "        RMSEs = np.load(save_dir + model_fn[:-3] + '_RMSE_zt.npy')\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.semilogy(validation_loss, label=exp_id + f' ({dim}D)')\n",
    "        plt.title('training')\n",
    "        \n",
    "        plt.subplot(1,4,3)\n",
    "        plt.plot([0,1], RMSEs[0]*np.ones(2), label=exp_id)\n",
    "        plt.title(f'RMSE {lead_time}h, z 500')\n",
    "        plt.xticks([])\n",
    "        plt.axis([-0.1, 1.1, 0, 600])\n",
    "        \n",
    "        plt.subplot(1,4,4)\n",
    "        plt.plot([0,1], RMSEs[1]*np.ones(2), label=exp_id)\n",
    "        plt.title(f'RMSE {lead_time}h, t 850')\n",
    "        plt.xticks([])\n",
    "        plt.axis([-0.1, 1.1, 0, 3.0])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylabel('validation error')\n",
    "plt.legend()\n",
    "#plt.subplot(1,4,3)\n",
    "#plt.legend()\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE per pixel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RMSEs_z = np.sqrt(np.mean((preds[:,0,:,:] - z500_test.isel(time=slice(lead_time, None)))**2, axis=0))\n",
    "RMSEs_t = np.sqrt(np.mean((preds[:,1,:,:] - t850_test.isel(time=slice(lead_time, None)))**2, axis=0))\n",
    "\n",
    "\n",
    "weights_lat = np.cos(np.deg2rad(z500_test.lat))\n",
    "weights_lat /= weights_lat.mean()\n",
    "\n",
    "wRMSEs_z = np.sqrt(\n",
    "    np.mean( ((preds[:,0,:,:] - z500_test.isel(time=slice(lead_time, None)))**2)*weights_lat, \n",
    "            axis=0))\n",
    "wRMSEs_t = np.sqrt(\n",
    "    np.mean( ((preds[:,1,:,:] - t850_test.isel(time=slice(lead_time, None)))**2)*weights_lat, \n",
    "            axis=0))\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(RMSEs_z)\n",
    "plt.title('RMSEs Z500')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(RMSEs_t)\n",
    "plt.title('RMSEs T850')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(wRMSEs_z)\n",
    "plt.title('weighted RMSEs Z500')\n",
    "plt.colorbar()\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(wRMSEs_t)\n",
    "plt.title('weighted RMSEs T850')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSEs per time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RMSEs_z = np.sqrt(np.mean((preds[:,0,:,:] - z500_test.isel(time=slice(lead_time, None)))**2, axis=[1,2]))\n",
    "RMSEs_t = np.sqrt(np.mean((preds[:,1,:,:] - t850_test.isel(time=slice(lead_time, None)))**2, axis=[1,2]))\n",
    "\n",
    "\n",
    "weights_lat = np.cos(np.deg2rad(z500_test.lat))\n",
    "weights_lat /= weights_lat.mean()\n",
    "\n",
    "wRMSEs_z = np.sqrt(\n",
    "    np.mean( ((preds[:,0,:,:] - z500_test.isel(time=slice(lead_time, None)))**2)*weights_lat, \n",
    "            axis=[1,2]))\n",
    "wRMSEs_t = np.sqrt(\n",
    "    np.mean( ((preds[:,1,:,:] - t850_test.isel(time=slice(lead_time, None)))**2)*weights_lat, \n",
    "            axis=[1,2]))\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(RMSEs_z)\n",
    "plt.title('RMSEs Z500')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(RMSEs_t)\n",
    "plt.title('RMSEs T850')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(wRMSEs_z)\n",
    "plt.title('weighted RMSEs Z500')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(wRMSEs_t)\n",
    "plt.title('weighted RMSEs T850')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quickplot of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dg = dg_test\n",
    "\n",
    "# variable names for display in figure\n",
    "var_names = {'geopotential' : 'geopotential at 500hPa', \n",
    "             'temperature' : 'temperature at 850hPa'}\n",
    "\n",
    "# pick time stamps to visualize\n",
    "idx = [2000, 2024, 2048, 2072, 2096, 2120] # index relative to start time of dataset !\n",
    "pre = dg[idx][0]\n",
    "preds = model_forward(torch.tensor(pre,requires_grad=False).to(device)).detach().numpy() \n",
    "    \n",
    "plt.figure(figsize=(16,3))\n",
    "idx_plot = [0,1,2,3,4]\n",
    "plt.imshow(np.hstack(preds[idx_plot,0,:,:]))\n",
    "for i in range(1,len(idx_plot)):\n",
    "    plt.plot(i*64*np.ones(2), [0, 31], 'k')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,3))\n",
    "idx_plot = [0,1,2,3,4]\n",
    "plt.imshow(np.hstack(preds[idx_plot,1,:,:]))\n",
    "for i in range(1,len(idx_plot)):\n",
    "    plt.plot(i*64*np.ones(2), [0, 31], 'k')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "#plt.savefig('/gpfs/home/nonnenma/projects/seasonal_forecasting/results/weatherbench/figs/T850_example_dreds_N5_dt24h.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
